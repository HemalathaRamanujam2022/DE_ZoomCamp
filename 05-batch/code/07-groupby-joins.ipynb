{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58655945-d01a-4bbd-ac3c-dcf03cc6ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e32550-3fe4-4d3c-9044-261baed4df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6dc9dc-e517-4413-8176-a928006eeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d816d2-40ae-4a04-bc99-11673a8edce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green.registerTempTable('green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2423411-cf43-441f-9735-3129db8ad713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    green\n",
    "WHERE\n",
    "    lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9eec0-aab3-4f00-8e2c-f5ac97084af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_green_revenue \\\n",
    "    .write.parquet('data/report/revenue/green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622da4ff-e029-4ad9-9c74-d9371efcf0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time with partition since the files are quite small and we can do fewer reshuffling during the group by stage\n",
    "df_green_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('data/report/revenue/green', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06d85e-3c6d-4794-a966-713b0907ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('data/pq/yellow/*/*')\n",
    "df_yellow.registerTempTable('yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df38de6-e349-4989-9d44-b99da325a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    date_trunc('hour', tpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM\n",
    "    yellow\n",
    "WHERE\n",
    "    tpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "    1, 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759691da-024b-4888-8a35-9ec52c9cd73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue \\\n",
    "    .write.parquet('data/report/revenue/yellow', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347b095-6b11-48f7-9531-19822bc557d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time with partition since the files are quite small and we can do fewer reshuffling during the group by stage\n",
    "df_yellow_revenue \\\n",
    "    .repartition(20) \\\n",
    "    .write.parquet('data/report/revenue/yellow', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd7716d-7135-4af3-99a4-5ebbaa6a0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed('amount', 'green_amount') \\\n",
    "    .withColumnRenamed('number_records', 'green_number_records')\n",
    "\n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "    .withColumnRenamed('number_records', 'yellow_number_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618bdc0-de87-4392-b35d-3a9614477b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are not reading the materialised tables, SPARK runs the entire stages once again based on the Spark SQL\n",
    "# You see this in the DAG visualisation on the browser at http://localhost:4040\n",
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on=['hour', 'zone'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905da95-dc0d-407e-ae7d-405768f097c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8fcf6-e409-49c3-8146-926de5a327e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have materialised the outputs from the summary table into parquest files, we will use them\n",
    "df_green_revenue = spark.read.parquet('data/report/revenue/green')\n",
    "df_yellow_revenue = spark.read.parquet('data/report/revenue/yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96bdff-2a88-4e4c-b953-a5581cec3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the same columns are there in both tables, we will rename then.\n",
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed('amount', 'green_amount') \\\n",
    "    .withColumnRenamed('number_records', 'green_number_records')\n",
    "\n",
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "    .withColumnRenamed('number_records', 'yellow_number_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce82eb8-5735-456a-8a7a-61dc623da0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp.join(df_yellow_revenue_tmp, on=['hour', 'zone'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931bbc1-9f73-49f1-ba4a-933eb5fcff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.write.parquet('data/report/revenue/total', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f2cd4-b890-44c0-bc7d-c2e234f8f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark.read.parquet('data/report/revenue/total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29edea3-fb29-4b73-9cb1-72d7390de878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751274e-8bca-4d46-bb9e-14fcab749074",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi+_zone_lookup.csv') \\\n",
    "    .write.parquet('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003abbfa-58da-451a-8db0-58e5ab3b7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599225a5-922e-400a-919f-d13b4df476bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('zones/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e5cdd-67e1-42ab-9331-2594229bf8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_join.join(df_zones, df_join.zone == df_zones.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0c5f2-1b99-4515-a9b4-2a2758824282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cffacce-042d-47ff-8c3f-b6b511e5ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61890a0-1e82-4145-96a5-2e8655c0a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.drop('LocationID', 'zone').write.parquet('tmp/revenue-zones')\n",
    "df_result.drop('LocationID', 'zone').write.parquet('tmp/revenue-zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70313-511c-474d-94db-9e7a16deda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
